<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Gaga groups any Gaussians in an open-world 3D scene and renders multi-view consistent segmentation.">
  <meta name="keywords" content="Open-world 3D Segmentation, 3D Gaussians, Scene Understanding">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Gaga: Group Any Gaussians via 3D-aware Memory Bank</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="./static/css/style.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/lady-gaga.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/script.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
            <i>Gaga</i> : Group Any Gaussians via 3D-aware Memory Bank
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://weijielyu.github.io/">Weijie Lyu</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://sunshineatnoon.github.io/">Xueting Li</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://abhijitkundu.info/">Abhijit Kundu</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://sites.google.com/site/yihsuantsai/">Yi-Hsuan Tsai</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://faculty.ucmerced.edu/mhyang/">Ming-Hsuan Yang</a><sup>1, 3</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California, Merced </span>
            <span class="author-block"><sup>2</sup>Nvidia </span>
            <span class="author-block"><sup>3</sup>Google </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/rqs5BuVFOok"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/weijielyu/Gaga"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>
          </div>
          <!-- Submission status -->
          <div class="title-row">
            <span class="title is-4 publication-venue">arXiv 2024</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="columns is-centered has-text-centered">
        <div class="column">
          <div class="switcher" data-switcher-title="Select Segmentation Model">
            <div data-switcher-label="SAM"></div>
            <div data-switcher-label="EntitySeg"></div>
          </div>
          <div id="image-compare-canvas" class="image-compare" data-before-label="RGB" data-after-label="Segmentation">
            <canvas id="canvas"></canvas>
          </div>
          <div class="video-bar base-row">
            <button id="play-btn" class="video-btn fa fa-lg fa-pause" onclick="play_pause()" style="margin-right: 0px;"></button>
          </div>
        </div>
      </div>
    </div>
    <h2 class="subtitle">
      <p>
        <i>Gaga</i> groups any Gaussians in an open-world 3D scene and renders multi-view consistent segmentation.
        We show 3D segmentation rendering results leveraging different 2D segmentation models, Segment Anything (SAM) and EntitySeg.
      </p>
      <!-- <p>
        <strong style="color:hsl(204, 86%, 53%)">EDIT</strong>: Change the color of cushion on <img src="static/images/footstool.png" width="58.5"> to <b style="color:#800000">maroon</b> and <img src="static/images/carpet.png" width="87.5"> to <b style="color:#000080">navy blue</b>; remove <img src="static/images/stuffed.png" width="75">
      </p> -->
    </h2>
    </div>
  </div>
</section>

<!-- Abstract. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce <i>Gaga</i>, a framework that reconstructs and segments open-world 3D scenes 
            by leveraging inconsistent 2D masks predicted by zero-shot segmentation models. Contrasted 
            to prior 3D scene segmentation approaches that heavily rely on video object tracking, 
            <i>Gaga</i> utilizes spatial information and effectively associates object masks across diverse camera 
            poses. By eliminating the assumption of continuous view changes in training images, <i>Gaga</i> 
            demonstrates robustness to variations in camera poses, particularly beneficial for sparsely 
            sampled images, ensuring precise mask label consistency. Furthermore, <i>Gaga</i> accommodates 
            2D segmentation masks from diverse sources and demonstrates robust performance with different 
            open-world zero-shot segmentation models, significantly enhancing its versatility. 
            Extensive qualitative and quantitative evaluations demonstrate that <i>Gaga</i> performs favorably against 
            state-of-the-art methods, emphasizing its potential for real-world applications such as scene 
            understanding and manipulation.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!--/ Abstract. -->

<!-- Paper video. -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/rqs5BuVFOok?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div>
</section>
<!--/ Paper video. -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <img src="static/images/overview.png" width="100%">
            </div>
          </div>
          <p>
            <strong>Overview of <i>Gaga</i>.</strong> <i>Gaga</i> reconstructs 3D scenes with Gaussian Splatting and
            adopts an open-world model to generate 2D segmentation masks. To eliminate the 2D
            mask label inconsistency, we design the 3D-aware mask association process, where a 3D-aware
            memory bank is employed to assign a consistent group ID across different views to
            each 2D mask based on the 3D Gaussians projected to that mask. Specifically,
            we find the corresponding Gaussians projected to each 2D mask and assign the mask
            with the group ID in the memory bank with the maximum overlapped Gaussians.
            After the 3D-aware mask association process, we use masks with multi-view
            consistent group IDs as pseudo labels to train an identity encoding on each 3D Gaussian
            for segmentation rendering.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- / Method-->

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Gallery</h2>
        <h3 class="title is-4">üó∫Ô∏è Open-world 3D Segmentation</h3>
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
                <h4 class="title is-5 is-centered has-text-centered"><b style="color:#808080">RGB</b></h4>
              </div>
            </div>
            <div class="column">
              <div class="content">
                <h4 class="title is-5 is-centered has-text-centered"><b style="color:#808080">Gaussian Grouping</b></h4>
              </div>
            </div>
            <div class="column">
              <div class="content">
                <h4 class="title is-5 is-centered has-text-centered"><b style="color:#808080"><i>Gaga</i></b></h4>
              </div>
            </div>
          </div>
        </div>
        <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/kitchen_entity.mov" type="video/mp4">
        </video>
        <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/room_entity.mov" type="video/mp4">
        </video>
        <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/counter_entity.mov" type="video/mp4">
        </video>
        <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/office_0_sam.mov" type="video/mp4">
        </video>
        <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/room_0_entity.mov" type="video/mp4">
        </video>
        <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/room_2_entity.mov" type="video/mp4">
        </video>
        <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/192_entity.mov" type="video/mp4">
        </video>
        <h3 class="title is-4"></h3>
        <h3 class="title is-4">üñåÔ∏è Scene Manipulation</h3>
        <h4 class="title is-5">
          Change the color of cushion on <img src="static/images/footstool.png" width="75"> to <b style="color:#800000">maroon</b>; remove <img src="static/images/stuffed.png" width="75">.
        </h4>
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
                <h4 class="title is-5 is-centered has-text-centered"><b style="color:#808080">RGB</b></h4>
              </div>
            </div>
            <div class="column">
              <div class="content">
                <h4 class="title is-5 is-centered has-text-centered"><b style="color:#808080">Gaussian Grouping</b></h4>
              </div>
            </div>
            <div class="column">
              <div class="content">
                <h4 class="title is-5 is-centered has-text-centered"><b style="color:#808080"><i>Gaga</i></b></h4>
              </div>
            </div>
          </div>
        </div>
        <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/room_app.mov" type="video/mp4">
        </video>
        </h4>
        <h4 class="title is-5"></h4>
        <h4 class="title is-5">
          Move <img src="static/images/armchair.png" width="75"> closer to the window.
        </h4>
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column">
              <div class="content">
                <h4 class="title is-5 is-centered has-text-centered"><b style="color:#808080">RGB</b></h4>
              </div>
            </div>
            <div class="column">
              <div class="content">
                <h4 class="title is-5 is-centered has-text-centered"><b style="color:#808080">Gaussian Grouping</b></h4>
              </div>
            </div>
            <div class="column">
              <div class="content">
                <h4 class="title is-5 is-centered has-text-centered"><b style="color:#808080"><i>Gaga</i></b></h4>
              </div>
            </div>
          </div>
        </div>
        <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
          <source src="./static/videos/office_3_app.mov" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered"> -->

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div> -->
    <!--/ Matting. -->

    <!-- Animation. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2> -->

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      <!-- </div>
    </div> -->
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  <!-- </div>
</section> -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/weijielyu" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> and <a href="https://github.com/chungmin99/garfield-website">GARField</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<video id="teaser" controls="false" loop autoplay muted class="videos" webkit-playsinline playsinline>
  <source src="static/videos/teaser.mov" type="video/mp4">
</video>

</body>
</html>
